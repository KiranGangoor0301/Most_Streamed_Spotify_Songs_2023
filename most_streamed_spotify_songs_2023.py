# -*- coding: utf-8 -*-
"""most-streamed-spotify-songs-2023.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XOQV969JDO1CIw45asD9Ui1J5xbs120M
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import matplotlib
import seaborn as sns
# %matplotlib inline

df = pd.read_csv("spotify-2023.csv", encoding='latin1')
df.head()

df.columns

df.shape

sample = df.head(100)
plt.plot(sample.index, sample['released_year'])

"""# 2. Data processing"""

df.rename(columns={'artist(s)_name':"artists_name"}, inplace=True)
df.rename(columns={'key':"song_key"}, inplace=True)
df.head()

df.duplicated().any()

df.info()

df.isna().sum()

df = df.drop('in_shazam_charts', axis=1)

df['in_deezer_playlists'] = df['in_deezer_playlists'].apply(lambda val: str(val).replace(',',''))
df['song_key'] = df['song_key'].fillna('undefined')

df['streams'] = pd.to_numeric(df['streams'], errors='coerce')
df['in_deezer_playlists'] = pd.to_numeric(df['in_deezer_playlists'], errors='coerce')
df['song_key'] = df['song_key'].astype('category')
df['mode'] = df['mode'].astype('category')

df.info()

df = df.dropna()

df.isna().sum()

"""# 3. Anomaly detection and processing

Checking the artists_count column
"""

df['artist_count'].hist(bins=100)

df.boxplot(column=['artist_count'])

df['artist_count'].describe()

"""Check the released_year column"""

df['released_year'].value_counts().plot.bar()

"""Checking the in_spotify_charts column"""

df['in_spotify_charts'].value_counts()

"""Checking the song_key column"""

df['song_key'].value_counts()

df['song_key'].describe()

df['song_key'].value_counts().plot.bar()

"""Checking the danceability_% column"""

df['danceability_%'].describe()

df.boxplot(column=['danceability_%'])

"""# 4. Data visualization

"""

# 20 most danceable tracks
df_danceability_20 = df.sort_values(by='danceability_%', ascending=False).head(20)

plt.figure()

sns.barplot(x = 'danceability_%', y = 'track_name', data = df_danceability_20)
plt.title('Top 20 tracks by "danceability"')
plt.xlabel('% danceability')
plt.ylabel('Name')

# 30 based on auditions
df_streaming = df.sort_values(by='streams', ascending=False).head(30)

plt.figure()

sns.barplot(x = 'streams', y = 'track_name', data = df_streaming)
plt.title('Top 30 listened to tracks in 2023')
plt.xlabel('Plays (billion)')
plt.ylabel('Name')

# Track releases by month

plt.figure()
sns.countplot(x = 'released_month', data = df, order=df['released_month'].value_counts().index)
plt.title('Popular months for track releases')
plt.xlabel('Month number (1 - January onwards)')
plt.ylabel('Number of releases')

# Danceability depends on BPM
df_bpm_sorted = df.sort_values(by='bpm', ascending=False)

plt.figure()

sns.lineplot(x = 'bpm', y = 'danceability_%', data = df_bpm_sorted)
plt.title('Dependence of "danceability" on BPM')
plt.xlabel('BPM')
plt.ylabel('Danceability')

# depends on the number of auditions on the tone
df_grouped = df.groupby(['song_key']).agg({'streams':[np.mean]})
df_grouped = df_grouped.reset_index()
df_grouped.columns = ['song_key', 'streams_mean']

plt.figure()

sns.barplot(x = 'song_key', y = 'streams_mean', data = df_grouped,
            order=df_grouped.sort_values('streams_mean', ascending=False)['song_key'])
plt.title('Dependence of the number of auditions on the key')
plt.xlabel('Key')
plt.ylabel('Average number of plays')

# number of plays by track parameters

df_pair_params = df.loc[:,['danceability_%', 'in_spotify_playlists','in_spotify_charts', 'bpm', 'streams']]

plt.figure()
sns.pairplot(data=df_pair_params, hue='streams')

"""# **LR 6**

# Classification
"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report

import numpy as np

df['hit_track'] = np.nan

conditions = [
    (df['in_spotify_playlists'] > 25000),
    (df['in_spotify_playlists'] > 10000) & (df['in_spotify_playlists'] <= 25000),
    (df['in_spotify_playlists'] > 1000)  & (df['in_spotify_playlists'] <= 10000),
    (df['in_spotify_playlists'] >= 0)    | (df['in_spotify_playlists'] <= 1000)
             ]
values = ['100%', '66%', '33%', '0%']
df['hit_track'] = np.select(conditions, values)
df['hit_track'] = df['hit_track'].astype('category')

df[['track_name','in_spotify_playlists', 'hit_track']].sample(10)

X = df[['in_spotify_playlists', 'released_year', 'in_apple_playlists', 'in_deezer_playlists']]
Y = df['hit_track']

X.sample(5)

Y.sample(5)

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=152)

print(X_train)

print(X_test)

dtree_model = DecisionTreeClassifier()
knn_model = KNeighborsClassifier(n_neighbors = 5)

dtree_model.fit(X_train, Y_train)
knn_model.fit(X_train, Y_train)

dtree_pred = dtree_model.predict(X_test)
knn_pred = knn_model.predict(X_test)

print(accuracy_score(dtree_pred, Y_test))
print(accuracy_score(knn_pred, Y_test))

print('Decision tree')
print(classification_report(dtree_pred, Y_test))

print('k-means')
print(classification_report(knn_pred, Y_test))

"""# Clustering"""

from sklearn.cluster import KMeans
from sklearn.cluster import Birch

X = df[['in_spotify_playlists', 'in_apple_playlists', 'in_deezer_playlists']]
Y = df['hit_track']

fig = plt.figure()
ax = fig.add_subplot(projection = '3d')

ax.scatter(X['in_spotify_playlists'], X['in_apple_playlists'], X['in_deezer_playlists'])
ax.set_xlabel('Spotify')
ax.set_ylabel('Apple')
ax.set_zlabel('Deezer')

kmeans = KMeans(n_clusters=2)
kmeans.fit(X)

print(kmeans.cluster_centers_)

def show_clusters(series, labels, centers, axes_labels):
    fig = plt.figure()
    ax = fig.add_subplot(projection = '3d')

    ax.scatter(*series, c = labels, cmap = 'rainbow')
    if centers:
        ax.scatter(*centers, color='black')

    ax.set_xlabel(axes_labels[0])
    ax.set_ylabel(axes_labels[1])
    ax.set_zlabel(axes_labels[2])

def clusters_count(labels):
    return len(set(labels))

show_clusters(series=[X['in_spotify_playlists'], X['in_apple_playlists'], X['in_deezer_playlists']],
             labels=kmeans.labels_,
             centers=[kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1],kmeans.cluster_centers_[:,2]],
             axes_labels=['Spotify', 'Apple', 'Deezer'],)

print(clusters_count(kmeans.labels_))

kmeans = KMeans(n_clusters=3)
kmeans.fit(X)

show_clusters(series=[X['in_spotify_playlists'], X['in_apple_playlists'], X['in_deezer_playlists']],
             labels=kmeans.labels_,
             centers=[kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1],kmeans.cluster_centers_[:,2]],
             axes_labels=['Spotify', 'Apple', 'Deezer'],)

print(clusters_count(kmeans.labels_))

kmeans = KMeans(n_clusters=4)
kmeans.fit(X)

show_clusters(series=[X['in_spotify_playlists'], X['in_apple_playlists'], X['in_deezer_playlists']],
             labels=kmeans.labels_,
             centers=[kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1],kmeans.cluster_centers_[:,2]],
             axes_labels=['Spotify', 'Apple', 'Deezer'],)

print(clusters_count(kmeans.labels_))

birch = Birch(n_clusters=3)
birch.fit(X)

show_clusters(series=[X['in_spotify_playlists'], X['in_apple_playlists'], X['in_deezer_playlists']],
             labels=birch.labels_,
             centers=None,
             axes_labels=['Spotify', 'Apple', 'Deezer'],)

print(clusters_count(birch.labels_))

birch = Birch(n_clusters=4)
birch.fit(X)

show_clusters(series=[X['in_spotify_playlists'], X['in_apple_playlists'], X['in_deezer_playlists']],
             labels=birch.labels_,
             centers=None,
             axes_labels=['Spotify', 'Apple', 'Deezer'],)

print(clusters_count(birch.labels_))

"""# **3. Simple and multiple linear regression**

# Simple Linear Regression
"""

import statsmodels.api as sm

df_pairs = df[['in_spotify_playlists', 'in_apple_playlists', 'in_deezer_playlists', 'released_year']]
sns.pairplot(df_pairs)

plt.scatter(df['in_spotify_playlists'], df['in_deezer_playlists'])
plt.xlabel('Spotify')
plt.ylabel('Deezer')

y = df['in_deezer_playlists']
x = df['in_spotify_playlists']
x = sm.add_constant(x)

ols_model = sm.OLS(y, x)
ols_results = ols_model.fit()

print(ols_results.summary())

fig = plt.figure()
fig = sm.graphics.plot_regress_exog(ols_results, 'in_spotify_playlists', fig = fig)

"""# Multiple Linear Regression"""

x = df[['in_apple_playlists', 'in_deezer_playlists','streams',]]
y = df['in_spotify_playlists']

from sklearn import linear_model

lr_model = linear_model.LinearRegression()
lr_model.fit(x, y)

print('Intercept:',lr_model.intercept_)
print('Coef:',lr_model.coef_)

sm_x = sm.add_constant(x)

ols_model = sm.OLS(y, sm_x)
ols_results = ols_model.fit()

print(ols_results.summary())

"""# **4. Forecasting using a neural network**"""

df['streams'].describe()

df['hit_track2'] = np.nan

conditions = [(df['streams'] >= 6*(10**8)), (df['streams'] < 6*(10**8))]
values = [1, 0]

df['hit_track2'] = np.select(conditions, values)
df['hit_track2'] = df['hit_track2'].astype('int16')

df[['track_name','streams','hit_track2']].sample(5)

X = df[['in_spotify_playlists', 'in_apple_playlists', 'in_deezer_playlists', 'streams']]
Y = df['hit_track2']

X.head(5)

Y.head(5)

from sklearn import preprocessing

min_max_scaler = preprocessing.MinMaxScaler()
X = min_max_scaler.fit_transform(X)

X_train, X_test_validate, Y_train, Y_test_validate = train_test_split(X, Y, test_size=0.30, random_state=152)
X_validate, X_test, Y_validate, Y_test = train_test_split(X_test_validate, Y_test_validate, test_size=0.5, random_state=152)

print(X_train.shape, Y_train.shape, X_validate.shape, Y_validate.shape, X_test.shape, Y_test.shape,)

from keras.models import Sequential
from keras.layers import Dense

model = Sequential([
    Dense(16, activation = 'relu', input_shape = (4,)),
    Dense(32, activation = 'relu'),
    Dense(1, activation = 'sigmoid'),
])

model.compile(optimizer = 'sgd',loss = 'binary_crossentropy', metrics = ['accuracy'])

history = model.fit(X_train, Y_train, batch_size = 32, epochs = 1000, validation_data = (X_validate, Y_validate))

model.evaluate(X_test, Y_test)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Val'], loc='upper right')
plt.show()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Val'], loc='lower right')
plt.show()

predictions = model.predict(X_test[:5])

X_test[:5]

predictions